{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0116e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All API keys loaded.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Multi-model microbiome-disease extraction benchmark.\n",
    "Direct API calls — no LAVA proxy.\n",
    "\n",
    "Requires these env vars in .env:\n",
    "    ANTHROPIC_API_KEY\n",
    "    OPENAI_API_KEY\n",
    "    GEMINI_API_KEY\n",
    "    MOONSHOT_API_KEY\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- API Keys ---\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "MOONSHOT_API_KEY = os.getenv(\"MOONSHOT_API_KEY\")\n",
    "\n",
    "# --- Config ---\n",
    "EXCLUDE_INDICES = {554, 638, 1025, 1946, 508, 979, 1597, 1776}\n",
    "SAMPLE_SIZE = 4\n",
    "SEED = 42\n",
    "MAX_CHARS = 48_000\n",
    "TIMEOUT = 180\n",
    "RETRY_MAX = 2\n",
    "RETRY_BACKOFF = 10\n",
    "CALL_DELAY = 3\n",
    "\n",
    "INPUT_FILE = \"MAIN_DATA.json\"\n",
    "OUTPUT_FILE = \"extraction_results.json\"\n",
    "\n",
    "# Quick check\n",
    "missing = []\n",
    "if not ANTHROPIC_API_KEY: missing.append(\"ANTHROPIC_API_KEY\")\n",
    "if not OPENAI_API_KEY: missing.append(\"OPENAI_API_KEY\")\n",
    "if not GEMINI_API_KEY: missing.append(\"GEMINI_API_KEY\")\n",
    "if not MOONSHOT_API_KEY: missing.append(\"MOONSHOT_API_KEY\")\n",
    "if missing:\n",
    "    print(f\"WARNING: Missing API keys: {', '.join(missing)}\")\n",
    "    print(\"Models with missing keys will be skipped.\")\n",
    "else:\n",
    "    print(\"All API keys loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbgt5z6b7el",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models registered: ['Claude Opus 4.6', 'GPT-5.2', 'Gemini 3 Pro', 'Kimi K2.5']\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# API call functions — one per provider\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def call_anthropic(system_prompt, user_prompt):\n",
    "    \"\"\"Claude Opus 4.6 via Anthropic Messages API.\"\"\"\n",
    "    resp = requests.post(\n",
    "        \"https://api.anthropic.com/v1/messages\",\n",
    "        headers={\n",
    "            \"x-api-key\": ANTHROPIC_API_KEY,\n",
    "            \"anthropic-version\": \"2023-06-01\",\n",
    "            \"content-type\": \"application/json\",\n",
    "        },\n",
    "        json={\n",
    "            \"model\": \"claude-opus-4-6\",\n",
    "            \"max_tokens\": 8192,\n",
    "            \"temperature\": 0.2,\n",
    "            \"system\": system_prompt,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": user_prompt}],\n",
    "        },\n",
    "        timeout=TIMEOUT,\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"content\"][0][\"text\"]\n",
    "\n",
    "\n",
    "def call_openai(system_prompt, user_prompt):\n",
    "    \"\"\"GPT-5.2 via OpenAI Chat Completions API.\"\"\"\n",
    "    resp = requests.post(\n",
    "        \"https://api.openai.com/v1/chat/completions\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        json={\n",
    "            \"model\": \"gpt-5.2\",\n",
    "            \"max_tokens\": 8192,\n",
    "            \"temperature\": 0.2,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "        },\n",
    "        timeout=TIMEOUT,\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def call_gemini(system_prompt, user_prompt):\n",
    "    \"\"\"Gemini 3 Pro via Google generateContent REST API.\"\"\"\n",
    "    resp = requests.post(\n",
    "        \"https://generativelanguage.googleapis.com/v1beta/models/gemini-3-pro-preview:generateContent\",\n",
    "        headers={\n",
    "            \"x-goog-api-key\": GEMINI_API_KEY,\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        json={\n",
    "            \"system_instruction\": {\"parts\": [{\"text\": system_prompt}]},\n",
    "            \"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": user_prompt}]}],\n",
    "            \"generationConfig\": {\n",
    "                \"maxOutputTokens\": 8192,\n",
    "                \"temperature\": 0.2,\n",
    "            },\n",
    "        },\n",
    "        timeout=TIMEOUT,\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "\n",
    "\n",
    "def call_moonshot(system_prompt, user_prompt):\n",
    "    \"\"\"Kimi K2.5 via Moonshot OpenAI-compatible API.\"\"\"\n",
    "    resp = requests.post(\n",
    "        \"https://api.moonshot.ai/v1/chat/completions\",\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {MOONSHOT_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        json={\n",
    "            \"model\": \"kimi-k2.5\",\n",
    "            \"max_tokens\": 8192,\n",
    "            \"temperature\": 0.6,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "        },\n",
    "        timeout=TIMEOUT,\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "# Model registry — maps name -> (call_fn, api_key)\n",
    "MODELS = {\n",
    "    \"Claude Opus 4.6\": (call_anthropic, ANTHROPIC_API_KEY),\n",
    "    \"GPT-5.2\":         (call_openai,    OPENAI_API_KEY),\n",
    "    \"Gemini 3 Pro\":    (call_gemini,    GEMINI_API_KEY),\n",
    "    \"Kimi K2.5\":       (call_moonshot,  MOONSHOT_API_KEY),\n",
    "}\n",
    "\n",
    "print(f\"Models registered: {list(MODELS.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8gso89hh8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Prompts\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are an expert medical data extraction specialist with deep knowledge of \"\n",
    "    \"microbiome research methodology and statistics. You must output ONLY valid JSON \"\n",
    "    \"— no markdown, no explanation, no preamble.\"\n",
    ")\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"You are an expert medical data extraction specialist with deep knowledge of microbiome research methodology and statistics.\n",
    "\n",
    "Your task: Extract microbiome-disease relationships from research papers with complete accuracy.\n",
    "\n",
    "## STEP 1: IDENTIFY STUDY TYPE\n",
    "First, determine what type of study this is:\n",
    "- Disease characterization (comparing diseased vs healthy)\n",
    "- Treatment/intervention study (testing drugs, supplements, transplants)\n",
    "- Observational/longitudinal study\n",
    "- Other\n",
    "\n",
    "## STEP 2: EXTRACT DISEASE INFORMATION\n",
    "- Primary disease or condition being studied\n",
    "- Related conditions mentioned\n",
    "- Control groups or comparison conditions\n",
    "\n",
    "## STEP 3: EXTRACT ALL BACTERIAL CHANGES\n",
    "For EACH bacterium mentioned with quantitative or qualitative changes:\n",
    "\n",
    "Extract at ALL taxonomic levels present:\n",
    "- Phylum level (if mentioned)\n",
    "- Family level (if mentioned)\n",
    "- Genus level (if mentioned)\n",
    "- Species level (if mentioned)\n",
    "\n",
    "For each bacterium, record:\n",
    "- Name (exact as written)\n",
    "- Taxonomic level (phylum/family/genus/species)\n",
    "- Direction: \"increased\", \"decreased\", \"unchanged\", or \"unclear\"\n",
    "- Quantitative data if available (percentages, fold-changes)\n",
    "- Statistical significance (p-value, confidence level)\n",
    "- Context (disease vs control, pre vs post treatment, etc.)\n",
    "\n",
    "## STEP 4: DISTINGUISH CAUSALITY\n",
    "CRITICAL: Determine if bacterial changes are:\n",
    "- Associated with DISEASE state (disease vs healthy)\n",
    "- Result of TREATMENT/INTERVENTION (pre vs post treatment)\n",
    "- Correlational only\n",
    "- Unknown/unclear\n",
    "\n",
    "## STEP 5: VERIFY COMPLETENESS\n",
    "- Did you extract EVERY bacterium mentioned with changes?\n",
    "- Did you check all tables, figures, and text?\n",
    "- Did you note if the paper says \"X bacteria and Y others\" (indicating incomplete listing)?\n",
    "- Did you check for contradictions between sections?\n",
    "\n",
    "## STEP 6: VALIDATE LOGIC\n",
    "- Do the directions make biological sense?\n",
    "- Are there any contradictory statements in the paper?\n",
    "- Is the statistical significance adequate (adjust for multiple comparisons)?\n",
    "- Were any bacteria mentioned in discussion but not measured in results?\n",
    "\n",
    "## OUTPUT FORMAT:\n",
    "Return a JSON object with this structure:\n",
    "\n",
    "{{\n",
    "  \"study_type\": \"disease_characterization | treatment_intervention | observational | other\",\n",
    "  \"study_design\": \"brief description\",\n",
    "  \"primary_disease\": \"disease name or null\",\n",
    "  \"related_conditions\": [\"condition1\", \"condition2\"],\n",
    "  \"sample_size\": \"number or not specified\",\n",
    "  \"statistical_methods\": \"brief description of analysis methods\",\n",
    "\n",
    "  \"bacteria_relationships\": [\n",
    "    {{\n",
    "      \"taxon_name\": \"exact name from paper\",\n",
    "      \"taxonomic_level\": \"phylum | family | genus | species\",\n",
    "      \"direction\": \"increased | decreased | unchanged | unclear\",\n",
    "      \"change_context\": \"disease_vs_control | treatment_effect | temporal | other\",\n",
    "      \"quantitative_data\": {{\n",
    "        \"disease_group\": \"percentage or value\",\n",
    "        \"control_group\": \"percentage or value\",\n",
    "        \"fold_change\": \"X-fold or null\",\n",
    "        \"p_value\": \"value or null\",\n",
    "        \"statistical_significance\": \"significant | not_significant | not_reported\"\n",
    "      }},\n",
    "      \"location_in_paper\": \"Table X | Figure Y | Results section | Discussion\",\n",
    "      \"confidence\": \"high | medium | low\",\n",
    "      \"notes\": \"any important context or caveats\"\n",
    "    }}\n",
    "  ],\n",
    "\n",
    "  \"extraction_metadata\": {{\n",
    "    \"total_bacteria_found\": 0,\n",
    "    \"completeness_assessment\": \"complete | partial | unclear\",\n",
    "    \"potential_missing_data\": \"description if incomplete\",\n",
    "    \"contradictions_found\": [\"list any contradictions\"],\n",
    "    \"limitations\": [\"any extraction limitations\"]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "## IMPORTANT RULES:\n",
    "1. Extract EVERY bacterium mentioned, even if changes are small or not significant\n",
    "2. If a paper says \"10 species changed\" but only lists 7, note the missing 3\n",
    "3. NEVER fabricate data - if direction is unclear, mark as \"unclear\"\n",
    "4. Distinguish between disease effects and treatment effects\n",
    "5. Note if findings didn't reach statistical significance after multiple comparison adjustment\n",
    "6. Include bacteria mentioned in discussion even if not in main results (note as \"discussion_only\")\n",
    "7. If genus-level and species-level data both exist, include both\n",
    "8. Check for bacteria that DECREASED in one section but are described differently elsewhere\n",
    "\n",
    "Now, extract from this paper:\n",
    "\n",
    "Paper text: {text}\n",
    "\n",
    "Output ONLY the JSON object, nothing else.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f0p4l985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpers loaded.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Helpers\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def parse_extraction(raw_text):\n",
    "    \"\"\"Parse extraction JSON from model response.\"\"\"\n",
    "    text = raw_text.strip()\n",
    "    # Strip markdown fences\n",
    "    match = re.search(r\"```(?:json)?\\s*\\n?(.*?)```\", text, re.DOTALL)\n",
    "    if match:\n",
    "        text = match.group(1).strip()\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "    # Find first { ... } block by brace matching\n",
    "    brace_start = text.find(\"{\")\n",
    "    if brace_start == -1:\n",
    "        return None\n",
    "    depth = 0\n",
    "    for i in range(brace_start, len(text)):\n",
    "        if text[i] == \"{\":\n",
    "            depth += 1\n",
    "        elif text[i] == \"}\":\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                try:\n",
    "                    return json.loads(text[brace_start : i + 1])\n",
    "                except json.JSONDecodeError:\n",
    "                    return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def is_junk_chunk(chunk):\n",
    "    \"\"\"Return True if a chunk should be skipped.\"\"\"\n",
    "    text = chunk.strip()\n",
    "    if len(text) < 30:\n",
    "        return True\n",
    "    if len(re.findall(r\"\\[DOI\\]|\\[PubMed\\]|\\[PMC\", text)) >= 3:\n",
    "        return True\n",
    "    if re.match(r\"10\\.\\d{4,}/\", text):\n",
    "        return True\n",
    "    if len(re.findall(r\"[\\w.+-]+@[\\w.-]+\\.\\w+\", text)) >= 3:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def merge_chunks(chunks):\n",
    "    \"\"\"Filter junk, merge with smart joining, truncate.\"\"\"\n",
    "    clean = [c for c in chunks if not is_junk_chunk(c)]\n",
    "    if not clean:\n",
    "        return \"\"\n",
    "    parts = [clean[0]]\n",
    "    for prev, cur in zip(clean, clean[1:]):\n",
    "        prev_stripped = prev.rstrip()\n",
    "        if prev_stripped and prev_stripped[-1] in \".!?\":\n",
    "            parts.append(\" \" + cur)\n",
    "        else:\n",
    "            parts.append(\". \" + cur)\n",
    "    merged = \"\".join(parts)\n",
    "    return merged[:MAX_CHARS] if len(merged) > MAX_CHARS else merged\n",
    "\n",
    "\n",
    "def call_with_retry(call_fn, system_prompt, user_prompt, model_name):\n",
    "    \"\"\"Wrap a call function with retry logic.\"\"\"\n",
    "    last_err = None\n",
    "    for attempt in range(1, RETRY_MAX + 2):\n",
    "        try:\n",
    "            return call_fn(system_prompt, user_prompt)\n",
    "        except Exception as e:\n",
    "            last_err = str(e)\n",
    "            if attempt <= RETRY_MAX:\n",
    "                print(f\"    Attempt {attempt} failed: {last_err}. Retrying in {RETRY_BACKOFF}s...\")\n",
    "                time.sleep(RETRY_BACKOFF)\n",
    "            else:\n",
    "                raise RuntimeError(f\"[{model_name}] All {RETRY_MAX + 1} attempts failed. Last: {last_err}\")\n",
    "\n",
    "print(\"Helpers loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16lz4cp6ylp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Total papers: 2026, valid: 2018, excluded: 8\n",
      "\n",
      "Sampled papers:\n",
      "  [1320] Oral Microbiota Linking Associations of Dietary Factors with Recurrent Oral Ulce\n",
      "  [230] Particle Size, Mass Concentration, and Microbiota in Dental Aerosols\n",
      "  [52] Evaluation of co-circulating pathogens and microbiome from COVID-19 infections\n",
      "  [1529] Rifaximin ameliorates influenza A virus infection-induced lung barrier damage by\n",
      "  Paper 1320: 122 chunks -> 38701 chars\n",
      "  Paper 230: 93 chunks -> 32628 chars\n",
      "  Paper 52: 133 chunks -> 48000 chars\n",
      "  Paper 1529: 139 chunks -> 48000 chars\n",
      "\n",
      "4 papers ready for extraction.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Load data & sample papers\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "print(\"Loading data...\")\n",
    "with open(INPUT_FILE) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "keys = list(data.keys())\n",
    "valid_keys = [k for i, k in enumerate(keys) if i not in EXCLUDE_INDICES]\n",
    "print(f\"Total papers: {len(keys)}, valid: {len(valid_keys)}, excluded: {len(keys) - len(valid_keys)}\")\n",
    "\n",
    "random.seed(SEED)\n",
    "sampled_keys = random.sample(valid_keys, SAMPLE_SIZE)\n",
    "\n",
    "print(f\"\\nSampled papers:\")\n",
    "for k in sampled_keys:\n",
    "    print(f\"  [{k}] {data[k]['name'][:80]}\")\n",
    "\n",
    "# Prepare merged text\n",
    "prepared = {}\n",
    "for k in sampled_keys:\n",
    "    paper = data[k]\n",
    "    merged = merge_chunks(paper[\"chunks\"])\n",
    "    prepared[k] = {\"title\": paper[\"name\"], \"text\": merged, \"orig_chunks\": len(paper[\"chunks\"])}\n",
    "    print(f\"  Paper {k}: {len(paper['chunks'])} chunks -> {len(merged)} chars\")\n",
    "\n",
    "print(f\"\\n{len(prepared)} papers ready for extraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lu7kp676wxg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Model: Claude Opus 4.6\n",
      "============================================================\n",
      "  [Claude Opus 4.6] Paper 1320: Oral Microbiota Linking Associations of Dietary Fa...\n",
      "    OK: 19 relationships extracted (52.5s)\n",
      "  [Claude Opus 4.6] Paper 230: Particle Size, Mass Concentration, and Microbiota ...\n",
      "    OK: 0 relationships extracted (16.3s)\n",
      "  [Claude Opus 4.6] Paper 52: Evaluation of co-circulating pathogens and microbi...\n",
      "    WARNING: JSON parse failed. Storing raw snippet.\n",
      "  [Claude Opus 4.6] Paper 1529: Rifaximin ameliorates influenza A virus infection-...\n",
      "    OK: 18 relationships extracted (53.2s)\n",
      "\n",
      "============================================================\n",
      "Model: GPT-5.2\n",
      "============================================================\n",
      "  [GPT-5.2] Paper 1320: Oral Microbiota Linking Associations of Dietary Fa...\n",
      "    Attempt 1 failed: Invalid header value b'Bearer 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\\n'. Retrying in 10s...\n",
      "    Attempt 2 failed: Invalid header value b'Bearer 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\\n'. Retrying in 10s...\n",
      "    FAILED: [GPT-5.2] All 3 attempts failed. Last: Invalid header value b'Bearer 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\\n'\n",
      "  [GPT-5.2] Paper 230: Particle Size, Mass Concentration, and Microbiota ...\n",
      "    Attempt 1 failed: Invalid header value b'Bearer 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\\n'. Retrying in 10s...\n",
      "    Attempt 2 failed: Invalid header value b'Bearer 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\\n'. Retrying in 10s...\n",
      "    FAILED: [GPT-5.2] All 3 attempts failed. Last: Invalid header value b'Bearer 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\\n'\n",
      "  [GPT-5.2] Paper 52: Evaluation of co-circulating pathogens and microbi...\n",
      "    Attempt 1 failed: Invalid header value b'Bearer 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\\n'. Retrying in 10s...\n",
      "    Attempt 2 failed: Invalid header value b'Bearer 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\\n'. Retrying in 10s...\n",
      "    FAILED: [GPT-5.2] All 3 attempts failed. Last: Invalid header value b'Bearer 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\\n'\n",
      "  [GPT-5.2] Paper 1529: Rifaximin ameliorates influenza A virus infection-...\n",
      "    Attempt 1 failed: Invalid header value b'Bearer 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\\n'. Retrying in 10s...\n",
      "    Attempt 2 failed: Invalid header value b'Bearer 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\\n'. Retrying in 10s...\n",
      "    FAILED: [GPT-5.2] All 3 attempts failed. Last: Invalid header value b'Bearer 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\\n'\n",
      "\n",
      "============================================================\n",
      "Model: Gemini 3 Pro\n",
      "============================================================\n",
      "  [Gemini 3 Pro] Paper 1320: Oral Microbiota Linking Associations of Dietary Fa...\n",
      "    OK: 17 relationships extracted (60.0s)\n",
      "  [Gemini 3 Pro] Paper 230: Particle Size, Mass Concentration, and Microbiota ...\n",
      "    OK: 0 relationships extracted (28.1s)\n",
      "  [Gemini 3 Pro] Paper 52: Evaluation of co-circulating pathogens and microbi...\n",
      "    WARNING: JSON parse failed. Storing raw snippet.\n",
      "  [Gemini 3 Pro] Paper 1529: Rifaximin ameliorates influenza A virus infection-...\n",
      "    OK: 16 relationships extracted (66.1s)\n",
      "\n",
      "============================================================\n",
      "Model: Kimi K2.5\n",
      "============================================================\n",
      "  [Kimi K2.5] Paper 1320: Oral Microbiota Linking Associations of Dietary Fa...\n",
      "    Attempt 1 failed: 429 Client Error: Too Many Requests for url: https://api.moonshot.ai/v1/chat/completions. Retrying in 10s...\n",
      "    Attempt 2 failed: 429 Client Error: Too Many Requests for url: https://api.moonshot.ai/v1/chat/completions. Retrying in 10s...\n",
      "    FAILED: [Kimi K2.5] All 3 attempts failed. Last: 429 Client Error: Too Many Requests for url: https://api.moonshot.ai/v1/chat/completions\n",
      "  [Kimi K2.5] Paper 230: Particle Size, Mass Concentration, and Microbiota ...\n",
      "    Attempt 1 failed: 429 Client Error: Too Many Requests for url: https://api.moonshot.ai/v1/chat/completions. Retrying in 10s...\n",
      "    Attempt 2 failed: 429 Client Error: Too Many Requests for url: https://api.moonshot.ai/v1/chat/completions. Retrying in 10s...\n",
      "    FAILED: [Kimi K2.5] All 3 attempts failed. Last: 429 Client Error: Too Many Requests for url: https://api.moonshot.ai/v1/chat/completions\n",
      "  [Kimi K2.5] Paper 52: Evaluation of co-circulating pathogens and microbi...\n",
      "    Attempt 1 failed: 429 Client Error: Too Many Requests for url: https://api.moonshot.ai/v1/chat/completions. Retrying in 10s...\n",
      "    Attempt 2 failed: 429 Client Error: Too Many Requests for url: https://api.moonshot.ai/v1/chat/completions. Retrying in 10s...\n",
      "    FAILED: [Kimi K2.5] All 3 attempts failed. Last: 429 Client Error: Too Many Requests for url: https://api.moonshot.ai/v1/chat/completions\n",
      "  [Kimi K2.5] Paper 1529: Rifaximin ameliorates influenza A virus infection-...\n",
      "    Attempt 1 failed: 429 Client Error: Too Many Requests for url: https://api.moonshot.ai/v1/chat/completions. Retrying in 10s...\n",
      "    Attempt 2 failed: 429 Client Error: Too Many Requests for url: https://api.moonshot.ai/v1/chat/completions. Retrying in 10s...\n",
      "    FAILED: [Kimi K2.5] All 3 attempts failed. Last: 429 Client Error: Too Many Requests for url: https://api.moonshot.ai/v1/chat/completions\n",
      "\n",
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Run extraction across all models\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "results = {}\n",
    "timings = {}\n",
    "\n",
    "for model_name, (call_fn, api_key) in MODELS.items():\n",
    "    if not api_key:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"SKIPPING {model_name} — no API key\")\n",
    "        print(f\"{'='*60}\")\n",
    "        continue\n",
    "\n",
    "    results[model_name] = {}\n",
    "    timings[model_name] = {}\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    for k in sampled_keys:\n",
    "        info = prepared[k]\n",
    "        print(f\"  [{model_name}] Paper {k}: {info['title'][:50]}...\")\n",
    "\n",
    "        user_prompt = USER_PROMPT_TEMPLATE.format(text=info[\"text\"])\n",
    "\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            raw = call_with_retry(call_fn, SYSTEM_PROMPT, user_prompt, model_name)\n",
    "            elapsed = time.time() - t0\n",
    "            timings[model_name][k] = round(elapsed, 1)\n",
    "\n",
    "            parsed = parse_extraction(raw)\n",
    "            if parsed is None:\n",
    "                print(f\"    WARNING: JSON parse failed. Storing raw snippet.\")\n",
    "                results[model_name][k] = {\"error\": \"JSON parse failed\", \"raw\": raw[:500]}\n",
    "            else:\n",
    "                n_rels = len(parsed.get(\"bacteria_relationships\", []))\n",
    "                print(f\"    OK: {n_rels} relationships extracted ({elapsed:.1f}s)\")\n",
    "                results[model_name][k] = parsed\n",
    "        except Exception as e:\n",
    "            print(f\"    FAILED: {e}\")\n",
    "            results[model_name][k] = {\"error\": str(e)}\n",
    "            timings[model_name][k] = None\n",
    "\n",
    "        time.sleep(CALL_DELAY)\n",
    "\n",
    "print(\"\\nExtraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "uh7hvshi2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to extraction_results.json\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Save results\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "output = {\n",
    "    \"papers_sampled\": sampled_keys,\n",
    "    \"timings\": timings,\n",
    "    \"results\": results,\n",
    "}\n",
    "with open(OUTPUT_FILE, \"w\") as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "print(f\"Saved to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "loxw4js1hk7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Paper | Model                |  Rels |    Time | Status\n",
      "---------+----------------------+-------+---------+-----------\n",
      "    1320 | Claude Opus 4.6      |    19 |   52.5s | OK\n",
      "    1320 | GPT-5.2              |   ERR |       — | [GPT-5.2] All 3 attempts failed. Last: I\n",
      "    1320 | Gemini 3 Pro         |    17 |   60.0s | OK\n",
      "    1320 | Kimi K2.5            |   ERR |       — | [Kimi K2.5] All 3 attempts failed. Last:\n",
      "     230 | Claude Opus 4.6      |     0 |   16.3s | OK\n",
      "     230 | GPT-5.2              |   ERR |       — | [GPT-5.2] All 3 attempts failed. Last: I\n",
      "     230 | Gemini 3 Pro         |     0 |   28.1s | OK\n",
      "     230 | Kimi K2.5            |   ERR |       — | [Kimi K2.5] All 3 attempts failed. Last:\n",
      "      52 | Claude Opus 4.6      |   ERR |   77.4s | JSON parse failed\n",
      "      52 | GPT-5.2              |   ERR |       — | [GPT-5.2] All 3 attempts failed. Last: I\n",
      "      52 | Gemini 3 Pro         |   ERR |   66.1s | JSON parse failed\n",
      "      52 | Kimi K2.5            |   ERR |       — | [Kimi K2.5] All 3 attempts failed. Last:\n",
      "    1529 | Claude Opus 4.6      |    18 |   53.2s | OK\n",
      "    1529 | GPT-5.2              |   ERR |       — | [GPT-5.2] All 3 attempts failed. Last: I\n",
      "    1529 | Gemini 3 Pro         |    16 |   66.1s | OK\n",
      "    1529 | Kimi K2.5            |   ERR |       — | [Kimi K2.5] All 3 attempts failed. Last:\n",
      "\n",
      "Model                | Avg Rels | Avg Time | Errors\n",
      "---------------------+----------+----------+-------\n",
      "Claude Opus 4.6      |     12.3 |    49.8s |      1\n",
      "GPT-5.2              |        — |        — |      4\n",
      "Gemini 3 Pro         |     11.0 |    55.1s |      1\n",
      "Kimi K2.5            |        — |        — |      4\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Benchmark summary\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "print(f\"\\n{'Paper':>8} | {'Model':<20} | {'Rels':>5} | {'Time':>7} | Status\")\n",
    "print(f\"{'-'*8}-+-{'-'*20}-+-{'-'*5}-+-{'-'*7}-+-{'-'*10}\")\n",
    "\n",
    "for k in sampled_keys:\n",
    "    for model_name in MODELS:\n",
    "        if model_name not in results:\n",
    "            continue\n",
    "        entry = results[model_name].get(k, {})\n",
    "        t = timings.get(model_name, {}).get(k)\n",
    "        t_str = f\"{t}s\" if t else \"—\"\n",
    "\n",
    "        if \"error\" in entry:\n",
    "            print(f\"{k:>8} | {model_name:<20} | {'ERR':>5} | {t_str:>7} | {entry['error'][:40]}\")\n",
    "        else:\n",
    "            n = len(entry.get(\"bacteria_relationships\", []))\n",
    "            print(f\"{k:>8} | {model_name:<20} | {n:>5} | {t_str:>7} | OK\")\n",
    "\n",
    "# Per-model aggregates\n",
    "print(f\"\\n{'Model':<20} | {'Avg Rels':>8} | {'Avg Time':>8} | {'Errors':>6}\")\n",
    "print(f\"{'-'*20}-+-{'-'*8}-+-{'-'*8}-+-{'-'*6}\")\n",
    "\n",
    "for model_name in MODELS:\n",
    "    if model_name not in results:\n",
    "        continue\n",
    "    rels = []\n",
    "    times = []\n",
    "    errs = 0\n",
    "    for k in sampled_keys:\n",
    "        entry = results[model_name].get(k, {})\n",
    "        if \"error\" in entry:\n",
    "            errs += 1\n",
    "        else:\n",
    "            rels.append(len(entry.get(\"bacteria_relationships\", [])))\n",
    "        t = timings.get(model_name, {}).get(k)\n",
    "        if t:\n",
    "            times.append(t)\n",
    "\n",
    "    avg_r = f\"{sum(rels)/len(rels):.1f}\" if rels else \"—\"\n",
    "    avg_t = f\"{sum(times)/len(times):.1f}s\" if times else \"—\"\n",
    "    print(f\"{model_name:<20} | {avg_r:>8} | {avg_t:>8} | {errs:>6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cedc2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
